{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSplicing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuyas/ImageSplicing/blob/master/ImageSplicing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3GKjKFdwmqU",
        "colab_type": "text"
      },
      "source": [
        "# Image Splicing\n",
        "\n",
        "## Import The required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyHA-IwGIXbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d32ee4f5-a750-4756-d9c1-4f144f76b6ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWwBRp6a_oPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.models import resnet152\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from sklearn import svm\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchvision import datasets\n",
        "import statistics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETasjrKDwtk1",
        "colab_type": "text"
      },
      "source": [
        "## Configuration Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHtnLfmstvb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 0.0003\n",
        "ILLUMINANT_TRAIN_DATAPATH = '/content/drive/My Drive/CTScan/run_2/train/'\n",
        "ILLUMINANT_VAL_DATAPATH = '/content/drive/My Drive/CTScan/run_2/test/'\n",
        "ILLUMINANT_TEST_DATAPATH = '/content/drive/My Drive/CTScan/run_2/test/'\n",
        "clf = svm.SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UbD9fMswxEy",
        "colab_type": "text"
      },
      "source": [
        "## The Resnet and Feature Extraction is defined here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBx_MB0GtNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Base(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Base, self).__init__()\n",
        "      self.model = models.resnet152(True)\n",
        "\n",
        "\n",
        "      # The feature extraction to create the DSF \n",
        "      self.feature_extract = nn.Sequential(self.model.conv1,\n",
        "                                           self.model.bn1,\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.MaxPool2d(3,2,1,1,ceil_mode=False),\n",
        "                                           self.model.layer1,\n",
        "                                           self.model.layer2,\n",
        "                                           self.model.layer3,\n",
        "                                           self.model.layer4)\n",
        "      \n",
        "      self.avgpool = self.model.avgpool\n",
        "      self.classifier = self.model.fc\n",
        "      self.dropout = nn.Dropout(0.5)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.fc1 = nn.Linear(1000,500)\n",
        "      self.fc2 = nn.Linear(500,250)\n",
        "      self.fc3 = nn.Linear(250,2)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "      self.gradients = None\n",
        "    \n",
        "    # The hook to get the gradient at the particular layer\n",
        "    def activations_hook(self,grad):\n",
        "      self.gradients = grad\n",
        "    \n",
        "    def get_gradient(self):\n",
        "        return self.gradients\n",
        "\n",
        "    def get_activations_hook(self):\n",
        "      return self.gradients\n",
        "\n",
        "    def get_activations(self,x):\n",
        "      return self.feature_extract(x)\n",
        "      \n",
        "    def forward(self,x):\n",
        "      x = self.feature_extract(x)\n",
        "      h = x.register_hook(self.activations_hook)\n",
        "      x = self.avgpool(x)\n",
        "      x = x.view((1,-1))\n",
        "      y = x\n",
        "      x = self.classifier(x)\n",
        "      # x = self.dropout(F.relu(self.fc1(x)))\n",
        "      # x = self.dropout(F.relu(self.fc2(x)))\n",
        "      # x = self.dropout(F.relu(self.fc3(x)))\n",
        "      # x = self.softmax(x)\n",
        "      return x,y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2jh2hBZB9Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkehEMt0wUvB",
        "colab_type": "text"
      },
      "source": [
        "## Transformations for the Images\n",
        "- Resize images to 224x224 (The input to the ResNet is 224x224)\n",
        "- convert to a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNyMN-UtzDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_TRANSFORM_IMG = transforms.Compose([\n",
        "    transforms.Resize(size=224),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    # transforms.RandomRotation(degrees = 15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "VAL_TRANSFORM_IMG = transforms.Compose([\n",
        "    transforms.Resize(size=224),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    # transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "train_data = ImageFolderWithPaths(root=ILLUMINANT_TRAIN_DATAPATH, transform=TRAIN_TRANSFORM_IMG)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
        "\n",
        "\n",
        "data = ImageFolderWithPaths(root=ILLUMINANT_TRAIN_DATAPATH, transform=TRAIN_TRANSFORM_IMG)\n",
        "data_loader = torch.utils.data.DataLoader(train_data,batch_size=1,shuffle=True,num_workers=0)\n",
        "\n",
        "\n",
        "val_data = ImageFolderWithPaths(root=ILLUMINANT_VAL_DATAPATH, transform=VAL_TRANSFORM_IMG)\n",
        "val_data_loader = torch.utils.data.DataLoader(val_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
        "\n",
        "test_data = ImageFolderWithPaths(root=ILLUMINANT_TEST_DATAPATH, transform=VAL_TRANSFORM_IMG)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCr_1sBpxEx8",
        "colab_type": "text"
      },
      "source": [
        "## Information about the datase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HfQthNJt0lP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "811e4810-8382-47a8-a455-e123771b25b5"
      },
      "source": [
        "dataiter = iter(train_data_loader)\n",
        "images, labels, paths = dataiter.next()\n",
        "print(\"Number of Training Examples: \", len(train_data))\n",
        "print(\"Number of Test Examples: \", len(test_data))\n",
        "print(\"Number of Validation Examples: \", len(val_data))\n",
        "print(\"Detected Classes are: \", train_data.class_to_idx)\n",
        "train_iter = iter(train_data_loader)\n",
        "images, labels, _ = train_iter.next()\n",
        "print(\"Image Shape on Batch size = {} \".format(images.size()))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training Examples:  128\n",
            "Number of Test Examples:  35\n",
            "Number of Validation Examples:  35\n",
            "Detected Classes are:  {'tampered': 0, 'true': 1}\n",
            "Image Shape on Batch size = torch.Size([1, 3, 224, 224]) \n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM-MAvW3xXQl",
        "colab_type": "text"
      },
      "source": [
        "## Initialize the model\n",
        "- create model\n",
        "- transfer it to the GPU\n",
        "- define the loss function (CrossEntropyLoss)\n",
        "- Adam Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXeqettNxZZ4",
        "colab_type": "text"
      },
      "source": [
        "## Function to generate the Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIVUPgeG1WY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def HeatmapGeneration(img,paths):\n",
        "  resnet.eval()\n",
        "  # img, _ = next(iter(data_loader))\n",
        "  pred,_ = resnet(img)\n",
        "  # print(pred.shape)\n",
        "  pred[:, 2].backward()\n",
        "\n",
        "  \"\"\"\n",
        "  get the gradient and neuron values from the penultimate layer\n",
        "  We take the ones with the greatest change and build the heatmap from it\n",
        "  \"\"\"\n",
        "  gradients = resnet.get_gradient()\n",
        "  pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "  activations = resnet.get_activations(img).detach()\n",
        "\n",
        "  for i in range(512):\n",
        "      activations[:, i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "      \n",
        "  heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "  heatmap = np.maximum(heatmap.cpu(), 0)\n",
        "  heatmap /= torch.max(heatmap)\n",
        "  # plt.matshow(heatmap.squeeze())\n",
        "  heatmap = heatmap.numpy()\n",
        "  paths = ''.join(paths)\n",
        "  p = paths.split(\"/\")\n",
        "  img = cv2.imread(paths)\n",
        "\n",
        "  \"\"\"\n",
        "  Resizing the heatmap to fit the image\n",
        "  \"\"\"\n",
        "  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HSV)\n",
        "  superimposed_img = heatmap * 0.4 + img\n",
        "  scale_percent = 20 # percent of original size\n",
        "  width = int(superimposed_img.shape[1] * scale_percent / 100)\n",
        "  height = int(superimposed_img.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "  resized = cv2.resize(superimposed_img, dim, interpolation = cv2.INTER_AREA)\n",
        "  # cv2_imshow(resized)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Convert the heatmap to HSV space and display only the H\n",
        "  \"\"\"\n",
        "  h, s, v = resized[:, :, 0], resized[:, :, 1], resized[:, :, 2]\n",
        "  # cv2_imshow(h)\n",
        "  resized = np.float32(h)\n",
        "  hist = cv2.calcHist([resized], [0], None, [256], [0, 256])\n",
        "  # cv2_imshow(hist)\n",
        "  # plt.show()\n",
        "  # if(p[-2] == 'tampered'):\n",
        "  print(p[-2],min(hist),max(hist),np.mean(hist),np.median(hist))\n",
        "  return max(hist)\n",
        "  # print(hist.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5dXpinM0xLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = Base()\n",
        "resnet.to(device)\n",
        "resnet.eval()\n",
        "dsf = []\n",
        "y_dsf = []\n",
        "k = 0\n",
        "t_iter = iter(data_loader)\n",
        "while k in range(128):\n",
        "  k=k+1\n",
        "  # print(k)\n",
        "  img,label,paths = t_iter.next()\n",
        "  img = img.cuda()\n",
        "  pred, features = resnet(img)\n",
        "  pred.argmax(dim=1)\n",
        "  pred[:,2].backward()\n",
        "  gradients = resnet.get_gradient()\n",
        "  pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "  activations = resnet.get_activations(img).detach()\n",
        "  dsf.append(features.cpu().data.numpy())\n",
        "  # p = paths.raw_input().split(\"/\")\n",
        "  paths = ''.join(paths)\n",
        "  p = paths.split(\"/\")\n",
        "  if p[-2] == 'tampered':\n",
        "      y_dsf.append(0)\n",
        "  else:\n",
        "      y_dsf.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-UntVc_JtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dsf = np.asarray(dsf)\n",
        "dsf = dsf.reshape(128,2048)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NP2ud1K7bx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "57413710-065b-40c7-aa4e-64d629e971ed"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "# clf = SVC(gamma='auto',class_weight={0:0.25,1:0.75})\n",
        "clf = SVC(gamma='auto',class_weight=\"balanced\")\n",
        "clf.fit(dsf, y_dsf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJzPjXZ_-AE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "f9193b11-7a63-44c4-eec6-13fbe60f9e58"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "classes =['tampered','normal']\n",
        "# confusion_matrix = torch.zeros(2, 2)\n",
        "correct_0 = 0\n",
        "correct_1 = 0\n",
        "count = 0\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "mean = 0\n",
        "threshold = 828\n",
        "resnet.eval()\n",
        "# with torch.no_grad():\n",
        "for data in test_data_loader:\n",
        "    total=total+1\n",
        "    images,labels,paths = data[0].to(device), data[1].to(device),data[2]\n",
        "    # images = to_pil(gray_world(from_pil(images))\n",
        "    outputs, features = resnet(images)\n",
        "\n",
        "    predicted = clf.predict(features.cpu().data.numpy())\n",
        "    paths = ''.join(paths)\n",
        "    p = paths.split(\"/\")\n",
        "    actual = 0\n",
        "    if p[-2] == 'tampered':\n",
        "        actual = 0\n",
        "        class_total[0] += 1\n",
        "    else:\n",
        "        actual = 1\n",
        "        class_total[1]+=1\n",
        "\n",
        "    if(predicted == 0):\n",
        "      print(\"1\",end=\" \")\n",
        "      count = count+1\n",
        "      mean_single = HeatmapGeneration(images,paths)\n",
        "      mean+=mean_single\n",
        "      if mean_single < 900:\n",
        "        predicted = 1\n",
        "    if(predicted == 0):\n",
        "      print(\"0\",end=\" \")\n",
        "      count = count+1\n",
        "      mean_single = HeatmapGeneration(images,paths)\n",
        "      mean+=mean_single\n",
        "      if mean_single > 1100:\n",
        "        predicted = 1\n",
        "    if(actual == predicted and actual == 0):\n",
        "      correct = correct+1\n",
        "      class_correct[0] +=1\n",
        "    elif(actual == predicted and actual == 1):\n",
        "      correct = correct+1\n",
        "      class_correct[1] +=1\n",
        "\n",
        "\n",
        "\n",
        "# print(mean,count,mean/count)\n",
        "\n",
        "acc = 100*correct/total\n",
        "print(correct)\n",
        "print(total)\n",
        "print('Testing accuracy: ' + str(acc))\n",
        "# print(confusion_matrix)\n",
        "\n",
        "for i in range(2):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "acc0 = 100 * class_correct[0] / class_total[0]\n",
        "acc1 = 100 * class_correct[1] / class_total[1]\n",
        "print_row_end = []\n",
        "row_end = [acc,acc0,acc1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 true [0.] [860.] 35.753906 21.0\n",
            "1 true [0.] [615.] 38.597656 33.5\n",
            "1 tampered [0.] [1562.] 33.371094 23.5\n",
            "0 tampered [0.] [1562.] 33.371094 23.5\n",
            "1 tampered [1.] [1029.] 40.035156 22.0\n",
            "0 tampered [1.] [1029.] 40.035156 22.0\n",
            "1 tampered [0.] [1302.] 32.617188 23.5\n",
            "0 tampered [0.] [1302.] 32.617188 23.5\n",
            "1 true [0.] [1028.] 37.851562 28.0\n",
            "0 true [0.] [1028.] 37.851562 28.0\n",
            "1 true [0.] [925.] 37.33203 21.0\n",
            "0 true [0.] [925.] 37.33203 21.0\n",
            "1 true [0.] [1545.] 33.871094 18.0\n",
            "0 true [0.] [1545.] 33.871094 18.0\n",
            "1 tampered [0.] [805.] 39.578125 19.0\n",
            "1 tampered [0.] [1205.] 39.808594 27.0\n",
            "0 tampered [0.] [1205.] 39.808594 27.0\n",
            "1 tampered [0.] [989.] 34.820312 26.0\n",
            "0 tampered [0.] [989.] 34.820312 26.0\n",
            "1 true [0.] [1260.] 33.125 26.5\n",
            "0 true [0.] [1260.] 33.125 26.5\n",
            "1 true [0.] [1408.] 34.628906 22.5\n",
            "0 true [0.] [1408.] 34.628906 22.5\n",
            "1 true [0.] [577.] 33.257812 27.5\n",
            "1 true [1.] [805.] 32.796875 25.0\n",
            "1 true [0.] [1323.] 36.070312 23.0\n",
            "0 true [0.] [1323.] 36.070312 23.0\n",
            "1 true [0.] [923.] 36.39453 25.5\n",
            "0 true [0.] [923.] 36.39453 25.5\n",
            "17\n",
            "35\n",
            "Testing accuracy: 48.57142857142857\n",
            "Accuracy of tampered :  0 %\n",
            "Accuracy of normal : 100 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTvceGOZE7K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Testing accuracy: 77.77777777777777\n",
        "Accuracy of tampered : 89 %\n",
        "Accuracy of normal : 50 %\n",
        "threshold - < 700"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0F2XjWlAmZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Testing accuracy: 68.57142857142857\n",
        "Accuracy of tampered : 61 %\n",
        "Accuracy of normal : 76 %\n",
        "threshold - > 900\n",
        "\n",
        "Testing accuracy: 68.57142857142857\n",
        "Accuracy of tampered : 83 %\n",
        "Accuracy of normal : 52 %\n",
        "threshold - > 1100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmBaxttpAOlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" GRAY WORLD\"\"\"\n",
        "Testing accuracy: 62.857142857142854\n",
        "Accuracy of tampered : 44 %\n",
        "Accuracy of normal : 82 %\n",
        "threshold = 750\n",
        "\n",
        "Testing accuracy: 65.71428571428571\n",
        "Accuracy of tampered : 50 %\n",
        "Accuracy of normal : 82 %\n",
        "threshold = 800"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnOEJaxDx8Qg",
        "colab_type": "text"
      },
      "source": [
        "## The running of the network\n",
        "- Forward Propogation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZkj64psMhUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Base()\n",
        "model.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# optimizer = optim.SGD(_params, lr=LEARNING_RATE, momentum=0.9)\n",
        "optimizer = optim.Adam(_params, lr=LEARNING_RATE, weight_decay=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UR2lAGKt2Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(epoch)\n",
        "    start = time.time()\n",
        "    correct = 0 \n",
        "    iterations = 0\n",
        "    iter_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i,data in enumerate(train_data_loader,0):\n",
        "        inputs, labels,paths = data[0].to(device), data[1].to(device),data[2]\n",
        "        optimizer.zero_grad()\n",
        "        outputs,_ = model(inputs)        \n",
        "        loss = criterion(outputs,labels)\n",
        "        iter_loss+=loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum()\n",
        "        iterations += 1\n",
        "\n",
        "    train_loss.append(iter_loss/iterations)\n",
        "    train_accuracy.append((100 * correct / len(train_data)))\n",
        "\n",
        "    # loss = 0.0\n",
        "    # correct = 0\n",
        "    # iterations = 0\n",
        "    # model.eval()\n",
        "\n",
        "    # for i, data in enumerate(val_data_loader):\n",
        "    #     inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    #     outputs = model(inputs)     \n",
        "    #     loss = criterion(outputs, labels)\n",
        "    #     loss += loss.item()\n",
        "    #     _, predicted = torch.max(outputs, 1)\n",
        "    #     correct += (predicted == labels).sum()\n",
        "\n",
        "    #     iterations+=1\n",
        "\n",
        "    # test_loss.append(loss/iterations)\n",
        "    # # Record the Testing accuracy\n",
        "    # test_accuracy.append((100 * correct / len(val_data)))\n",
        "    stop = time.time()\n",
        "    # print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Validation Loss: {:.3f}, Validation Acc: {:.3f}, Time: {:.3f}s'\n",
        "    #            .format(epoch+1, EPOCHS, train_loss[-1], train_accuracy[-1], test_loss[-1], test_accuracy[-1], stop-start))\n",
        "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Time: {:.3f}s'\n",
        "               .format(epoch+1, EPOCHS, train_loss[-1], train_accuracy[-1], stop-start))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-kZ0Pf8yDkD",
        "colab_type": "text"
      },
      "source": [
        "## Testing of the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux0HeRGat5Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "classes =['NORMAL','SPLICING']\n",
        "# confusion_matrix = torch.zeros(2, 2)\n",
        "correct_0 = 0\n",
        "correct_1 = 0\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for data in test_data_loader:\n",
        "      images,labels,paths = data[0].to(device), data[1].to(device),data[2]\n",
        "      outputs, op_1 = model(images)\n",
        "      _, predicted = torch.max(outputs,1)\n",
        "      total += labels.size(0)\n",
        "      c = (predicted == labels).squeeze()\n",
        "      for i in range(BATCH_SIZE):\n",
        "        if(predicted == 1):\n",
        "          HeatmapGeneration(images,paths)\n",
        "      for i in range(4):\n",
        "          # print(labels)\n",
        "          label = labels\n",
        "          # print(c)\n",
        "          class_correct[label] += c.item()\n",
        "          class_total[label] += 1\n",
        "      correct+=(predicted == labels).sum().item()\n",
        "      for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "              confusion_matrix[t.long(), p.long()] += 1\n",
        "acc = 100*correct/total\n",
        "print(correct)\n",
        "print(total)\n",
        "print('Testing accuracy: ' + str(acc))\n",
        "# print(confusion_matrix)\n",
        "\n",
        "for i in range(2):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "acc0 = 100 * class_correct[0] / class_total[0]\n",
        "acc1 = 100 * class_correct[1] / class_total[1]\n",
        "print_row_end = []\n",
        "row_end = [acc,acc0,acc1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjDbMROBIPZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}